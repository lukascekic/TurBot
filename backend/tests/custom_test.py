#!/usr/bin/env python3
"""
TESTING TEMPLATE - Use this structure for all future tests

This template is based on test_identical_queries_simple_structure.py which works correctly.
Key components that make tests work:
1. Async functions with proper OpenAI client setup
2. Full RAG pipeline: self-querying â†’ query expansion â†’ vector search â†’ response generation
3. Only location filter used to avoid ChromaDB limitations
4. Direct service initialization (no factory functions)
5. Proper error handling and result display
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import logging
from openai import AsyncOpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Setup OpenAI client
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

from services.self_querying_service import SelfQueryingService
from services.query_expansion_service import QueryExpansionService
from services.vector_service import VectorService
from services.response_generator import ResponseGenerator

async def test_your_feature():
    """Template test function - replace with your specific test"""
    
    # Initialize services (ALWAYS USE THIS PATTERN)
    self_querying = SelfQueryingService(client)
    query_expansion = QueryExpansionService(client)
    vector_service = VectorService()  # No parameters needed
    response_generator = ResponseGenerator(client)
    
    # Your test queries
    test_queries = [
        "Jel imas neki smestaj u Rimu za 4 osobe?",
        "Jel ima nesto za leto ove godine?"
    ]
    
    print("ğŸ”„ TESTING YOUR FEATURE")
    print("=" * 70)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ¯ TEST {i}: '{query}'")
        print("-" * 50)
        
        try:
            # Step 1: Self-Querying (ALWAYS INCLUDE)
            print("1ï¸âƒ£ Self-Querying Analysis...")
            structured_query = await self_querying.parse_query(query)
            
            print(f"   âœ… Intent: {structured_query.intent}")
            print(f"   âœ… Semantic Query: {structured_query.semantic_query}")
            print(f"   âœ… Location: {structured_query.filters.get('location')}")
            print(f"   âœ… Confidence: {structured_query.confidence}")
            
            # Step 2: Query Expansion (ALWAYS INCLUDE)
            print("\n2ï¸âƒ£ Query Expansion...")
            expanded_query = await query_expansion.expand_query_llm(structured_query.semantic_query)
            print(f"   âœ… Expanded: {expanded_query[:100]}...")
            
            # Step 3: Vector Search (USE ONLY LOCATION FILTER)
            print("\n3ï¸âƒ£ Vector Search...")
            
            # USE ALL FILTERS - let vector service handle hierarchy
            simple_filters = structured_query.filters
            
            from models.document import SearchQuery
            search_query = SearchQuery(
                query=expanded_query,  # Use expanded query, not original
                filters=simple_filters,  # ONLY location filter
                limit=3
            )
            search_results = vector_service.search(search_query)
            
            print(f"   âœ… Found {len(search_results.results)} results")
            print(f"   âœ… Filters used: {simple_filters}")
            
            # Display results with FULL METADATA
            for j, result in enumerate(search_results.results[:2]):
                doc_name = result.metadata.source_file or "Unknown document"
                print(f"     â€¢ Result {j+1}: {doc_name} (similarity: {result.similarity_score:.3f})")
                print(f"       ğŸ“ Destination: {result.metadata.destination}")
                print(f"       ğŸ·ï¸ Category: {result.metadata.category}")
                print(f"       ğŸ’° Price Range: {result.metadata.price_range}")
                print(f"       ğŸ—“ï¸ Travel Month: {result.metadata.travel_month}")
                print(f"       ğŸŒ¸ Seasonal: {result.metadata.seasonal}")
                print(f"       ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Family Friendly: {result.metadata.family_friendly}")
                print(f"       ğŸšŒ Transport: {result.metadata.transport_type}")
                print(f"       ğŸ“… Duration: {result.metadata.duration_days} days")
                print(f"       ğŸ¯ Confidence: {result.metadata.confidence_score}")
                print(f"       ğŸ“„ Text Preview: {result.text[:100]}...")
                print()
            
            # Step 4: Response Generation (ALWAYS - even with no results)
            print("\n4ï¸âƒ£ Response Generation...")
            
            # Convert SearchResult objects to dict format
            search_results_dict = []
            if search_results and search_results.results:
                for result in search_results.results:
                    search_results_dict.append({
                        'content': result.text,
                        'metadata': result.metadata.model_dump(),
                        'similarity': result.similarity_score,
                        'document_name': result.metadata.source_file or 'Unknown'
                    })
            
            # Generate response even with empty results
            response = await response_generator.generate_response(
                search_results=search_results_dict,
                structured_query=structured_query
            )
            
            print(f"   âœ… Response generated ({len(response.response)} chars)")
            print(f"   âœ… Confidence: {response.confidence}")
            print(f"   âœ… Sources: {len(response.sources)}")
            
            # Display full response
            print(f"\nğŸ‰ **COMPLETE AI RESPONSE:**")
            print("=" * 50)
            print(response.response)
            print("=" * 50)
        
        except Exception as e:
            print(f"   âŒ Test {i} failed: {e}")
            import traceback
            traceback.print_exc()
        
        print("-" * 50)
    
    print("\n" + "=" * 70)
    print("ğŸ TESTING COMPLETE")

async def test_simple_vector_search():
    """Simple vector search test without full pipeline"""
    
    print("ğŸ” SIMPLE VECTOR SEARCH TEST")
    print("=" * 50)
    
    vector_service = VectorService()
    
    # Test simple searches
    test_cases = [
        {"query": "hotel", "location": "Amsterdam"},
        {"query": "aranÅ¾man", "location": "Istanbul"},
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª Test {i}: Query='{test_case['query']}', Location='{test_case['location']}'")
        
        from models.document import SearchQuery
        search_query = SearchQuery(
            query=test_case['query'],
            filters={"location": test_case['location']},
            limit=3
        )
        
        results = vector_service.search(search_query)
        print(f"   Results: {len(results.results)}")
        
        for j, result in enumerate(results.results[:1]):
            print(f"   â€¢ {result.metadata.source_file} (similarity: {result.similarity_score:.3f})")

if __name__ == "__main__":
    # Run your tests
    asyncio.run(test_your_feature())
    print("\n" + "="*80 + "\n")
    asyncio.run(test_simple_vector_search()) 